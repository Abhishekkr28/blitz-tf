{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clothing Image Classification\n",
    "\n",
    "#### Team Name: Blitz\n",
    "#### Team ID: 6460727\n",
    "#### Members: Vivaswat Sinha, Abhishek Kumar, Dhruv, Apoorv Garg\n",
    "### =======================================\n",
    "\n",
    "##### Welcome to Team Blitz Myntra HackerRamp Hackerthon Submission.\n",
    "We would Like to present Our Project \"Clothing Recommendation System\" developed using Densenet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import pickle\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from PIL import ImageFile\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limiting GPU usage to 90%\n",
    "#### Prevent sudden crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "K.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    '''\n",
    "        This function is used to load the images and their file names to a list.\n",
    "        \n",
    "        parameters:\n",
    "            path: path to the images directory.\n",
    "        \n",
    "        variable:\n",
    "            images: stores the images.\n",
    "                dimension: (num_img, 1, 224, 244, 3)\n",
    "            \n",
    "            image_names: stores the name of image files\n",
    "                dimension: (num_img, 1)\n",
    "        \n",
    "        return:\n",
    "            images, image_names\n",
    "    '''\n",
    "    \n",
    "    images = []\n",
    "    image_names = []\n",
    "    \n",
    "    # starting timer\n",
    "    startTime = time.time()\n",
    "    print('Loading Images!')\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    # accessing image directory\n",
    "    for subfolder in os.listdir(path):\n",
    "        \n",
    "        # accessing image subfolder\n",
    "        folder = os.path.join('Images', subfolder)\n",
    "        for file in os.listdir(folder):\n",
    "            \n",
    "            # loading image file\n",
    "            img = image.load_img(os.path.join(folder, file), target_size=(224, 224))\n",
    "            \n",
    "            # converting image into an array of dimension (1, img_dim)\n",
    "            img = np.array([image.img_to_array(img)])\n",
    "            \n",
    "            # saving image and image name in arrays\n",
    "            image_names.append(file)\n",
    "            images.append(img)\n",
    "            \n",
    "            count += 1\n",
    "            if count%100 == 0:\n",
    "                print('Loaded {} images'.format(count))\n",
    "    print('Loading Done!')\n",
    "    print('Time Taken to Load Images: {0:.2f} seconds'.format(time.time() - startTime))\n",
    "    \n",
    "    return images, image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(images, image_names):\n",
    "    '''\n",
    "        This function is used to plot some of the images using matplotlib.\n",
    "        \n",
    "        parameters:\n",
    "            images: array of images.\n",
    "            image_names: array of all image file names.\n",
    "        \n",
    "        variable:\n",
    "            fig: matplotlib figure\n",
    "            ax: axis of matplotlib figure\n",
    "    '''\n",
    "    \n",
    "    # creating figure with 6 subplots\n",
    "    fig, ax = plt.subplots(2, 3)\n",
    "    \n",
    "    # setting size of figure\n",
    "    fig.set_size_inches(9, 5)\n",
    "    \n",
    "    # setting subplot spacing\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=1)\n",
    "\n",
    "    # plotting 6 random images\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            index = random.randint(1, len(image_names))\n",
    "            ax[i,j].text(-10, -20, image_names[index-1])\n",
    "            ax[i,j].imshow(images[index-1][0]/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tag_data(file, image_names):\n",
    "    '''\n",
    "        This function is used to load the tags for training. \n",
    "        The tags are then converted to multiple lists and dictionary for use.\n",
    "        \n",
    "        parameter:\n",
    "            file: path to csv file.\n",
    "            image_names: array containing names of all image files.\n",
    "        \n",
    "        variable:\n",
    "            DatasetCSV: pandas dataframe that stores the csv data.\n",
    "            Class: list containing all the Class for classification.\n",
    "            ClassItem: dictionary mapping Class with a list of all its distinct values.\n",
    "            Tags: numpy array containing the different tags for an image.\n",
    "                dimension: (num_img, 3)\n",
    "            fileName: numpy array containing name of image file.\n",
    "                dimension: (num_img, 1)\n",
    "            img_tag_map: dictionary mapping file name with their tags.\n",
    "                format: \n",
    "                    filename: tags\n",
    "        \n",
    "        return:\n",
    "            Class, ClassItem, img_tag_map, Tags, fileName\n",
    "    '''\n",
    "    \n",
    "    print('Loading CSV')\n",
    "    \n",
    "    # reading csv file\n",
    "    DatasetCSV = pd.read_csv(file)\n",
    "    \n",
    "    print('CSV loaded')\n",
    "    # extracting classes\n",
    "    Class = list(DatasetCSV.columns[1:])\n",
    "    \n",
    "    img_tag_map = {}\n",
    "    fileName = []\n",
    "    Tags = []\n",
    "    ClassItem = {}\n",
    "    \n",
    "    # mapping image file name with tags\n",
    "    for index, row in DatasetCSV.iterrows():\n",
    "        img_tag_map[row['filename']] = np.array([row['type'], row['subType'], row['color']])\n",
    "        fileName.append(row['filename'])\n",
    "    \n",
    "    # ordering tags according to dataset\n",
    "    for name in image_names:\n",
    "        Tags.append(img_tag_map[name])\n",
    "    Tags = np.array(Tags)\n",
    "    \n",
    "    # creating ClassItem dictionary\n",
    "    for index in range(Tags.shape[1]):\n",
    "        ClassItem[Class[index]] = np.unique(Tags[:, index])\n",
    "    \n",
    "    print(\"Total Number of Classes: {}\".format(len(Class)))\n",
    "    for cl in Class:\n",
    "        print(\"{}: {}\".format(cl, ClassItem[cl]) )\n",
    "\n",
    "    print('Total Number of Images: {}'.format(len(fileName)))\n",
    "    \n",
    "    return Class, ClassItem, img_tag_map, Tags, fileName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_images(images, names):\n",
    "    '''\n",
    "        This function encodes the image into a 1D Vector which will be used for classification later. If the encoded\n",
    "        \n",
    "        parameters:\n",
    "            images: array of all images\n",
    "            names: name of images\n",
    "        variable:\n",
    "            model: DenseNet121 model with weights of imagenet. The last  layer of the densenet model are removed.\n",
    "            X_encoded: numpy array containing the encoded image vectors.\n",
    "                dimension: (num_img, 1024)\n",
    "            name_encode_map: dictionary mapping image file name and encoded vector\n",
    "        \n",
    "        return:\n",
    "            model, X_encoded\n",
    "    '''\n",
    "    \n",
    "    # loading densenet121 model\n",
    "    model = DenseNet121(weights='imagenet')\n",
    "    # removing last Layer\n",
    "    model = Model(model.input, model.layers[-2].output)\n",
    "    \n",
    "    # Starting timer\n",
    "    startTime = time.time()\n",
    "    name_encode_map = {}\n",
    "    X_encoded = []\n",
    "    \n",
    "    # If images are already encoded, then load then from pickle file\n",
    "    if('encoded_train_data.pkl' in os.listdir('saved') and 'encoded_train_array.pkl' in os.listdir('saved')):\n",
    "        print('encoded data already present!')\n",
    "        print('reading files....')\n",
    "        \n",
    "        # loading name_encode_map\n",
    "        with (open('saved/encoded_train_data.pkl', \"rb\")) as openfile:\n",
    "            name_encode_map = pickle.load(openfile)\n",
    "\n",
    "        # Loading X_encoded\n",
    "        with open('saved/encoded_train_array.pkl', 'rb') as f:\n",
    "            while True:\n",
    "                try:\n",
    "                    X_encoded.append(pickle.load(f))\n",
    "                except EOFError:\n",
    "                    break\n",
    "    # Else encode all the images using densenet model\n",
    "    else:\n",
    "        print('Starting Encoding Process!')\n",
    "        for index, img in enumerate(images):\n",
    "            \n",
    "            # Encoding image\n",
    "            vec = model.predict(img)\n",
    "            \n",
    "            # reshaping vector into 1D vector\n",
    "            vec.reshape(-1)\n",
    "            \n",
    "            # mapping image vector to image file name\n",
    "            name_encode_map[names[index]] = vec[0]\n",
    "            \n",
    "            # adding image vector to training array\n",
    "            X_encoded.append(vec[0])\n",
    "            \n",
    "            if index%200 == 0:\n",
    "                curTime = time.time()\n",
    "                print(\"{0} images Encoded... Time Elapsed: {1:.2f} seconds\".format(index, curTime - startTime))\n",
    "\n",
    "        # saving encoded data\n",
    "        with open('saved/encoded_train_data.pkl', 'wb') as f:\n",
    "            pickle.dump(name_encode_map, f)\n",
    "        with open('saved/encoded_train_array.pkl', 'wb') as f:\n",
    "            pickle.dump(X_encoded, f)\n",
    "    endTime = time.time()\n",
    "    print(\"Done Encoding... Total Time: {0:.2f}\".format(endTime - startTime))\n",
    "    \n",
    "    X_encoded = np.array(X_encoded)\n",
    "    X_encoded = X_encoded.reshape((-1, 1024))\n",
    "    \n",
    "    return model, X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(Class, X_train, Y_train, epoch=100, batch=25, opti='adam'):\n",
    "    '''\n",
    "        This Function creates a simple ANN for classification.\n",
    "        \n",
    "        parameters:\n",
    "            Class: list of all Classes.\n",
    "            X_train: array of images to train.\n",
    "            Y_train: labels of images to train.\n",
    "            epoch: numer of epochs.\n",
    "            batch: batch size.\n",
    "            opti: optimizer.\n",
    "        \n",
    "        variable:\n",
    "            model_1: simple ANN network\n",
    "        \n",
    "        return:\n",
    "            model_1\n",
    "    '''\n",
    "    \n",
    "    # Creating model\n",
    "    model_1 =Input(shape=(1024,))\n",
    "    dense1 = Dense((512), activation='relu')(model_1)\n",
    "    drop = Dropout(0.3)(dense1)\n",
    "    dense2 = Dense((256), activation='relu')(drop)\n",
    "    dense3 = Dense((64), activation='relu')(dense2)\n",
    "    output = Dense(len(ClassItem[Class]), activation='softmax')(dense3)\n",
    "    \n",
    "    # training model\n",
    "    model_1 = Model(model_1, output)\n",
    "    model_1.compile(optimizer=opti, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model_1.fit(X_train, Y_train, epochs = epoch, batch_size=batch, shuffle=True, validation_split=0.2)\n",
    "    \n",
    "    return model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Class, X_train, Y_train, num_epoch, batch_size):\n",
    "    '''\n",
    "        This function is used to train multiple models for all the classes. \n",
    "        It also saves the model and LabelEncoder data in h5 and npy file respectively for prediction.\n",
    "        \n",
    "        parameters:\n",
    "            Class: list containing all the classes\n",
    "                dimension: (3,)\n",
    "            X_train: image vectors.\n",
    "                dimension: (num_img, 1024)\n",
    "            Y_train: Tags.\n",
    "                dimension: (num_img, 3)\n",
    "            num_epoch: number of epochs to train on.\n",
    "            batch_size: batch size.\n",
    "        \n",
    "        variable:\n",
    "            label_encoder: LabelEncoder object.\n",
    "            newMode: model trained for a class.\n",
    "            models: list containing all class models.\n",
    "        \n",
    "        return:\n",
    "            models\n",
    "                \n",
    "    '''\n",
    "    models = []\n",
    "    for i in range(Y_train.shape[1]):\n",
    "        \n",
    "        # encoding Y_train\n",
    "        label_encoder = LabelEncoder()\n",
    "        Y_train = Y_train[:, i]\n",
    "        Y_train = np.array(label_encoder.fit_transform(Y_train))\n",
    "        \n",
    "        # training model on current class\n",
    "        newModel = create_model(Class[i], X_train, Y_train, num_epoch, batch_size)\n",
    "        models.append(newModel)\n",
    "        \n",
    "        newModel.save('saved/model/model_'+Class[i]+'.h5')\n",
    "        np.save(\"saved/encoder/\"+Class[i]+\"_label.npy\", label_encoder.classes_)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, image_names = load_data('Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(images, image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class, ClassItem, desc, Y_train, filename = load_tag_data('Dataset.csv', image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Densenet, X_train = encode_images(images, image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = train(Class, X_train, Y_train, 150, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
